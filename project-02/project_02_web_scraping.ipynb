{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "424f56b3",
   "metadata": {},
   "source": [
    "Bài toán: Sau khi bitcoin và các đồng tiền ảo sụt giảm, công ty có nhu cầu khảo sát thông tin về card đồ họa thông qua một website. Yêu cầu team Data Engineer collect và thống kê các thông tin tại danh mục trên website: [https://www.newegg.com](https://www.newegg.com/GPUs-Video-Graphics-Cards/SubCategory/ID-48?Tid=7709) để phía đội kinh doanh có cơ sở triển khai chiến dịch mới.\n",
    "\n",
    "Mô tả cụ thể:\n",
    "\n",
    "- Nguồn dữ liệu cần crawl là danh mục sau: https://www.newegg.com/GPUs-Video-Graphics-Cards/SubCategory/ID-48?Tid=7709\n",
    "- Thông tin cần lấy:\n",
    "    - ItemID\n",
    "    - Title\n",
    "    - Branding (hang)\n",
    "    - Rating\n",
    "    - So luong rating\n",
    "    - Price (Current Price) --> Chuyen doi duoi dang number\n",
    "    - Shipping (Free, ko ship hay mat phi)\n",
    "    - Image URL \n",
    "    - Cac thong tin chi tiet ve san pham: \n",
    "        - MaxResolution\n",
    "        - DisplayPort\n",
    "        - HDMI\n",
    "        - DirectX\n",
    "        - Model\n",
    "- Số lượng: Toàn bộ các sản phẩm của 100 pages (khoảng 3600 sản phẩm)\n",
    "- Thông tin sau khi collect đẩy vào một cơ sở dữ liệu MySQL\n",
    "    - Thêm một cột total price dựa trên giá shipping \n",
    "    - Thông tin chi tiết về sản phẩm lưu dưới dạng JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7de218bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import requests\n",
    "import webbrowser\n",
    "import re\n",
    "import pandas as pd\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_scraping():\n",
    "    \n",
    "    ls_item_id = []\n",
    "    ls_title = []\n",
    "    ls_brand = []\n",
    "    ls_rating = []\n",
    "    ls_number_of_rating = []\n",
    "    ls_price_current = []\n",
    "    ls_shipping = []\n",
    "    ls_image_url = []\n",
    "    ls_details = []\n",
    "    \n",
    "    for i in range(1, 101):\n",
    "        if i == 1:\n",
    "            url = \"https://www.newegg.com/GPUs-Video-Graphics-Cards/SubCategory/ID-48\"\n",
    "        else:\n",
    "            url = \"https://www.newegg.com/GPUs-Video-Graphics-Cards/SubCategory/ID-48/Page-\" + str(i)\n",
    "\n",
    "        # Fetching content of one page    \n",
    "        resp = requests.get(url)\n",
    "        soup = BeautifulSoup(resp.text, 'html.parser')\n",
    "\n",
    "        # Filter items cell \n",
    "        items = soup.findAll('div', attrs={'class': re.compile('item-container')})\n",
    "\n",
    "        # Extract information\n",
    "\n",
    "        for item in items:\n",
    "\n",
    "            # Get item_id\n",
    "            item_id = item['id']\n",
    "            ls_item_id.append(item_id)\n",
    "\n",
    "            # Get title\n",
    "            try:\n",
    "                title = item.find('a').find('img')['title']\n",
    "                ls_title.append(title)\n",
    "            except:\n",
    "                title = 'Not title'\n",
    "                ls_title.append(title)\n",
    "                \n",
    "            # Get branding\n",
    "            try:\n",
    "                brand = item.find('a', attrs={'class': re.compile('item-brand')}).find('img')['title']\n",
    "                ls_brand.append(brand)\n",
    "            except: \n",
    "                brand = 'Not brand'\n",
    "                ls_brand.append(brand)\n",
    "                \n",
    "            # Get rating\n",
    "            try:\n",
    "                rating = item.find('i', attrs={'class': re.compile(\"rating\")})['aria-label'].split()[1]\n",
    "                ls_rating.append(rating)\n",
    "            except:\n",
    "                rating = 'not rating'\n",
    "                ls_rating.append(rating)\n",
    "\n",
    "            # Get number of rating\n",
    "            try:\n",
    "                number_of_rating = item.find(\"span\", attrs={'class': 'item-rating-num'}).string.strip(\"()\")\n",
    "                ls_number_of_rating.append(number_of_rating)\n",
    "            except:\n",
    "                number_of_rating = 0\n",
    "                ls_number_of_rating.append(number_of_rating)\n",
    "\n",
    "            # Get price current and convert to number\n",
    "            try:\n",
    "                price_current = item.find('li', attrs={'class': 'price-current'}).find(['strong']).string + \\\n",
    "                            items[0].find('li', attrs={'class': 'price-current'}).find(['sup']).string\n",
    "\n",
    "                price_current = float(price_current.replace(',',''))\n",
    "\n",
    "                ls_price_current.append(price_current)\n",
    "                \n",
    "            except:\n",
    "                price_current = 0\n",
    "                ls_price_current.append(price_current)\n",
    "                \n",
    "            # Get Shipping\n",
    "            try:\n",
    "                shipping = item.find('li', attrs={'class': 'price-ship'}).string\n",
    "                ls_shipping.append(shipping)\n",
    "            except:\n",
    "                shipping = 'Not information about shipping'\n",
    "                ls_shipping.append(shipping)\n",
    "                \n",
    "            # Get image URL\n",
    "            try:\n",
    "                image_url = item.find('img')['src']\n",
    "                ls_image_url.append(image_url)\n",
    "            except:\n",
    "                image_url = 'Not information about image url'\n",
    "                ls_image_url.append(image_url)\n",
    "                \n",
    "            # Get details of product\n",
    "            dict_details = {}\n",
    "            try:\n",
    "                for d in item.findAll('li'):\n",
    "                    if d.text.startswith('Max Resolution'):\n",
    "                        dict_details[\"Max_Resolution\"] = d.text.split(\":\")[1]\n",
    "                    elif d.text.startswith('DisplayPort'):\n",
    "                        dict_details[\"Display_Port\"] = d.text.split(\":\")[1]\n",
    "                    elif d.text.startswith('HDMI'):\n",
    "                        dict_details[\"HDMI\"] = d.text.split(\":\")[1]\n",
    "                    elif d.text.startswith('DirectX'):\n",
    "                        dict_details[\"DirectX\"] = d.text.split(\":\")[1]\n",
    "                    elif d.text.startswith('Model'):\n",
    "                        dict_details[\"Model\"] = d.text.split(\":\")[1]\n",
    "                    else:\n",
    "                        continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            ls_details.append(dict_details)\n",
    "            \n",
    "    return ls_item_id, ls_title, ls_brand, ls_rating, ls_number_of_rating, \\\n",
    "           ls_price_current, ls_shipping, ls_image_url, ls_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48943bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke function scraping web\n",
    "\n",
    "ls_item_id, ls_title, ls_brand, ls_rating, ls_number_of_rating, \\\n",
    "ls_price_current, ls_shipping, ls_image_url, ls_details = web_scraping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f8cd9b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records:  3604 \n",
      "\n",
      "item_id              object\n",
      "title                object\n",
      "brand                object\n",
      "rating               object\n",
      "number_of_rating     object\n",
      "price_current       float64\n",
      "shipping             object\n",
      "image_url            object\n",
      "details              object\n",
      "total_price         float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Create Dataframe from lists\n",
    "\n",
    "df = pd.DataFrame(list(zip(ls_item_id, ls_title, ls_brand, ls_rating, ls_number_of_rating, \\\n",
    "                           ls_price_current, ls_shipping, ls_image_url, ls_details)),\n",
    "                 columns=['item_id','title','brand','rating','number_of_rating','price_current','shipping', \\\n",
    "                          'image_url', 'details'])\n",
    "\n",
    "# Convert columns details to str\n",
    "\n",
    "df[\"details\"] = df[\"details\"].astype('str')\n",
    "\n",
    "# Calculate price shipping \n",
    "\n",
    "df['price_shipping'] = df['shipping'].apply(lambda x: float(x.rstrip(\" Shipping\").lstrip(\"$\")) \n",
    "                                            if x != 'Free Shipping' and x != 'Special Shipping' else 0)\n",
    "\n",
    "# Create total price\n",
    "\n",
    "df['total_price'] = df['price_current'] + df['price_shipping']\n",
    "\n",
    "# Drop columns price shipping\n",
    "\n",
    "df.drop(columns='price_shipping', inplace=True)\n",
    "\n",
    "# Describe dataframe\n",
    "\n",
    "print('Number of records: ',len(df), '\\n')\n",
    "\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "47113666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3604"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "# Credentials to database connection\n",
    "hostname=\"localhost\"\n",
    "dbname=\"db_project2\"\n",
    "uname=\"tanlee\"\n",
    "pwd=\"17012021*Th\"\n",
    "\n",
    "\n",
    "# Create SQLAlchemy engine to connect to MySQL Database\n",
    "\n",
    "engine = create_engine(\"mysql+pymysql://{user}:{pw}@{host}/{db}\" \\\n",
    "                       .format(host=hostname, db=dbname, user=uname, pw=pwd))\n",
    "\n",
    "# Write dataframe to mysql database\n",
    "\n",
    "df.to_sql(name='products', if_exists='replace', con=engine, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
